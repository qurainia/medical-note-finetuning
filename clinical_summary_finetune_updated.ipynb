{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Note Generation: From SFT to RL Fine-tuning with NeMo Microservices\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); padding: 25px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "<h2 style=\"color: #00d4ff; margin-top: 0;\">Training LLMs to Match a Specific Clinical Note Format & Style</h2>\n",
    "<p style=\"color: #e0e0e0; font-size: 14px;\">\n",
    "This notebook demonstrates how to fine-tune LLMs to generate clinical notes in a <strong>specific format and style</strong> using two complementary techniques:\n",
    "</p>\n",
    "<ul style=\"color: #e0e0e0; font-size: 14px;\">\n",
    "<li><strong>SFT (Supervised Fine-Tuning)</strong> — Teaches the target FORMAT (structure, sections, information extraction)</li>\n",
    "<li><strong>DPO (Direct Preference Optimization)</strong> — Refines the STYLE (phrasing, verbosity)</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "### The Problem We're Solving\n",
    "\n",
    "**Clinical notes need to follow specific formats and styles:**\n",
    "- Different healthcare systems have different documentation standards\n",
    "- Physicians spend time reformatting notes to match institutional templates\n",
    "- Consistency in note format improves downstream workflows (billing, handoffs, EHR integration)\n",
    "\n",
    "**Our Goal:** Finetune an LLM to generate clinical notes that match a **specific format and writing style**.\n",
    "\n",
    "<div style=\"background: #1a1a2e; padding: 15px; border-radius: 8px; border-left: 4px solid #00d4ff; margin: 10px 0;\">\n",
    "<strong style=\"color: #00d4ff;\">Key Distinction:</strong> <span style=\"color: #e0e0e0;\">This is a <strong>format/style transformation task</strong>, not a clinical reasoning task. The medical content is already in the conversation. We are teaching the model how to present it in a specific format.</span>\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### The Dataset: Augmented Clinical Notes\n",
    "\n",
    "We use the **[AGBonnet/augmented-clinical-notes](https://huggingface.co/datasets/AGBonnet/augmented-clinical-notes)** dataset from Hugging Face.\n",
    "\n",
    "### What's in the Dataset?\n",
    "\n",
    "| Field | Description | Example |\n",
    "|-------|-------------|---------|\n",
    "| `conversation` | Doctor-patient dialogue transcript | \"Doctor: What brings you in today? Patient: I have chest pain...\" |\n",
    "| `note` | Corresponding clinical note | \"HISTORY OF PRESENT ILLNESS: 45-year-old male presents with...\" |\n",
    "\n",
    "### Why This Dataset?\n",
    "\n",
    "1. **Consistent target format** — Notes follow a specific documentation style we want the model to learn\n",
    "2. **Paired data** — Each conversation has a corresponding note in our target format\n",
    "3. **Format examples** — Shows the model exactly how to structure and present clinical information  \n",
    "4. **Sufficient size** — 30K+ examples enable the model to learn the format patterns\n",
    "\n",
    "<div style=\"background: #16213e; padding: 12px; border-radius: 6px; margin: 10px 0;\">\n",
    "<strong style=\"color: #ffd700;\"> The dataset teaches FORMAT, not medicine:</strong> <span style=\"color: #e0e0e0;\">We assume the model already knows medical terminology from pre-training. We're teaching it our specific way of organizing and presenting that information.</span>\n",
    "</div>\n",
    "\n",
    "### Dataset Splits\n",
    "\n",
    "| Split | Size | Purpose |\n",
    "|-------|------|---------|\n",
    "| Training | 1,000 | Model learns patterns |\n",
    "| Validation | 100 | Hyperparameter tuning |\n",
    "| Test | 100 | Final evaluation |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We'll Cover\n",
    "\n",
    "| Stage | Approach | What It Does |\n",
    "|-------|----------|--------------|\n",
    "| **Part 1** | Infrastructure Setup | Deploy NeMo Microservices + LLaMA 3.1 8B |\n",
    "| **Part 2** | Baseline Evaluation | See how base model handles the task (spoiler: wrong format) |\n",
    "| **Part 3** | SFT with LoRA | **Teach FORMAT** — structure, sections, info extraction |\n",
    "| **Part 4** | Post-SFT Evaluation | Verify format is correct |\n",
    "| **Part 5** | DPO Alignment | **Refine STYLE** — phrasing, verbosity, conventions |\n",
    "| **Part 6** | Final Evaluation | Verify style matches preferences |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "### Virtual Env\n",
    "First create a virtual env in the terminal and select it as the kernel for this notebook.\n",
    "```sh\n",
    "python3 -m venv .myvenv\n",
    "source .myvenv/bin/activate\n",
    "pip3 install ipykernel dotenv\n",
    "python3 -m ipykernel install --user --name=dli_venv --display-name \"DLI Venv\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Keys Setup\n",
    "\n",
    "This notebook requires two API keys to access the necessary resources:\n",
    "\n",
    "1. **NVIDIA NGC API Key**  \n",
    "   - Used for pulling models and resources from NVIDIA's NGC registry.\n",
    "   - Obtain your NGC API key by logging in at [NGC NVIDIA](https://ngc.nvidia.com/), navigating to your profile (top right), and clicking \"Setup\" → \"Get API Key\".\n",
    "   - [NGC API Key Documentation](https://docs.nvidia.com/ngc/ngc-overview/index.html#generating-api-key)\n",
    "\n",
    "2. **Hugging Face API Token**  \n",
    "   - Needed for accessing models and datasets from Hugging Face Hub.\n",
    "   - Create or log in to your account at [Hugging Face](https://huggingface.co/).\n",
    "   - Go to your Settings → \"Access Tokens\" and generate a token with \"read\" access.\n",
    "   - [HF Token Documentation](https://huggingface.co/docs/hub/security-tokens)\n",
    "\n",
    "#### How to Provide Your Keys\n",
    "\n",
    "Run the cell below to automatically create a `.env` file from the `.env.example` template. Then edit the `.env` file and replace the placeholder values with your actual API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Create .env from example if needed\n",
    "if not Path('.env').exists():\n",
    "    shutil.copy('.env.example', '.env')\n",
    "    print(\"✓ .env created from example. Please update it with your real API keys.\")\n",
    "else:\n",
    "    print(\"✓ .env file already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "NGC_API_KEY = os.getenv(\"NGC_API_KEY\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Steps\n",
    "\n",
    "### Part 1: Set Docker Storage Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the partition that has enough free space\n",
    "!df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the partition mounted on `/` has enough storage space, there's no need to change the Docker storage location, we can skip to Part 2: Setup Software Packages now.\n",
    "\n",
    "Otherwise, proceed to change the Docker storage location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume we found it to be mounted to /ephemeral and not /\n",
    "!mkdir -p /ephemeral/docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit `/etc/docker/daemon.json` and add the following line:\n",
    "```json\n",
    "\"data-root\": \"/ephemeral/docker\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "new_docker_storage_location = '/ephemeral/docker'\n",
    "\n",
    "# Read existing docker config or start fresh\n",
    "try:\n",
    "    result = subprocess.run(['sudo', 'cat', '/etc/docker/daemon.json'], \n",
    "                          capture_output=True, text=True)\n",
    "    config = json.loads(result.stdout) if result.stdout.strip() else {}\n",
    "except:\n",
    "    config = {}\n",
    "print(\"config: \", config)\n",
    "# Add/update the data-root setting\n",
    "config['data-root'] = new_docker_storage_location\n",
    "# Write back to json format\n",
    "config_json = json.dumps(config, indent=2)\n",
    "# update and view new content in /etc/docker/daemon.json\n",
    "ret = subprocess.run(f'echo \\'{config_json}\\' | sudo tee /etc/docker/daemon.json', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then reload docker\n",
    "!sudo systemctl daemon-reload\n",
    "!sudo systemctl restart docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.5: Fix UFW Firewall for Docker/Minikube Networking\n",
    "\n",
    "If UFW (Uncomplicated Firewall) is active, its default FORWARD policy may block Docker container traffic, preventing minikube from reaching external registries like `registry.k8s.io`. This will cause `ImagePullBackOff` errors when enabling addons like ingress.\n",
    "\n",
    "The fix below:\n",
    "1. Changes UFW's default forward policy to ACCEPT (persistent)\n",
    "2. Adds an iptables rule to allow Docker container traffic\n",
    "3. Makes the iptables rule persistent across reboots\n",
    "\n",
    "**Run this cell before running the deployment script.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Fix UFW firewall to allow Docker container traffic (only runs if UFW is active)\n",
    "if sudo ufw status | grep -q \"Status: active\"; then\n",
    "    echo \"UFW is active, configuring forward policy...\"\n",
    "    sudo sed -i 's/DEFAULT_FORWARD_POLICY=\"DROP\"/DEFAULT_FORWARD_POLICY=\"ACCEPT\"/' /etc/default/ufw\n",
    "    sudo ufw reload\n",
    "    echo \"✓ UFW forward policy set to ACCEPT\"\n",
    "else\n",
    "    echo \"UFW is not active, skipping UFW config\"\n",
    "fi\n",
    "\n",
    "# Add iptables rule to allow Docker container traffic (required for minikube to reach external registries)\n",
    "sudo iptables -C DOCKER-USER -j ACCEPT 2>/dev/null || sudo iptables -I DOCKER-USER -j ACCEPT\n",
    "echo \"✓ iptables DOCKER-USER rule configured\"\n",
    "\n",
    "# Make the iptables rule persistent by creating a script that runs after Docker starts\n",
    "cat << 'EOF' | sudo tee /etc/docker/docker-post-start.sh > /dev/null\n",
    "#!/bin/bash\n",
    "# Allow Docker container traffic to reach external networks\n",
    "iptables -C DOCKER-USER -j ACCEPT 2>/dev/null || iptables -I DOCKER-USER -j ACCEPT\n",
    "EOF\n",
    "sudo chmod +x /etc/docker/docker-post-start.sh\n",
    "\n",
    "# Create systemd override to run the script after Docker starts\n",
    "sudo mkdir -p /etc/systemd/system/docker.service.d\n",
    "cat << 'EOF' | sudo tee /etc/systemd/system/docker.service.d/iptables-fix.conf > /dev/null\n",
    "[Service]\n",
    "ExecStartPost=/etc/docker/docker-post-start.sh\n",
    "EOF\n",
    "sudo systemctl daemon-reload\n",
    "echo \"✓ iptables rule made persistent via systemd\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Setup Software Packages\n",
    "\n",
    "We will be installing packages for the following software requirements for using minikube.\n",
    "\n",
    "- NGC account. If you don’t have an NGC account, you can create one on the [NGC Sign In page](https://ngc.nvidia.com/signin).\n",
    "\n",
    "- Docker 27 or later.\n",
    "\n",
    "- [Minikube](https://minikube.sigs.k8s.io/docs/start/) version 1.33 or later.\n",
    "\n",
    "- NVIDIA Container Toolkit v1.16.2 or higher. Refer to the [Installing the NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html).\n",
    "\n",
    "- NVIDIA GPU Driver 560.35.03 or higher. Refer to [Driver Installation Guide](https://docs.nvidia.com/datacenter/tesla/driver-installation-guide/index.html).\n",
    "\n",
    "- Kubernetes CLI, kubectl. Refer to [Install and Set Up kubectl on Linux](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/) in the Kubernetes documentation.\n",
    "\n",
    "- Helm CLI, helm. Refer to the [Helm documentation](https://helm.sh/docs/intro/install).\n",
    "\n",
    "- Hugging Face CLI. You need this for uploading dataset files through NeMo Data Store. Refer to the [Hugging Face Hub CLI user guide](https://huggingface.co/docs/huggingface_hub/en/guides/cli) and the [Hugging Face Hub installation guide](https://huggingface.co/docs/huggingface_hub/en/installation).\n",
    "\n",
    "- The jq command line tool. Refer to the [Download jq](https://jqlang.org/download/) page for instructions.\n",
    "\n",
    "\n",
    "Reference: https://docs.nvidia.com/nemo/microservices/latest/get-started/setup/requirements.html#nemo-ms-get-started-requirements\n",
    "\n",
    "#### Install minikube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LO https://github.com/kubernetes/minikube/releases/latest/download/minikube-linux-amd64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo install minikube-linux-amd64 /usr/local/bin/minikube && rm minikube-linux-amd64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"$(cat kubectl.sha256)  kubectl\" | sha256sum --check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a checksum OK message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n",
    "# check the kubectl version\n",
    "!kubectl version --client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install helm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install curl gpg apt-transport-https --yes\n",
    "!curl -fsSL https://packages.buildkite.com/helm-linux/helm-debian/gpgkey | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null\n",
    "!echo \"deb [signed-by=/usr/share/keyrings/helm.gpg] https://packages.buildkite.com/helm-linux/helm-debian/any/ any main\" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list\n",
    "!sudo apt-get update && sudo apt-get install helm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Hugging Face CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LsSf https://hf.co/cli/install.sh | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the hf cli installation path to $PATH. For example, if the above installation command showed: `[INFO] CLI location: /home/shadeform/.local/bin/hf`, then you will want to add `/home/shadeform/.local/bin` to `$PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Define the new paths to add\n",
    "new_path_dir = \"/home/shadeform/.local/bin\"\n",
    "python3_venv_path = \"/home/shadeform/.myvenv/bin/python3\"\n",
    "\n",
    "paths_to_remove = [\n",
    "    \"/home/shadeform/.venv/bin\",\n",
    "    \"/usr/lib/python310.zip\",\n",
    "    \"/usr/lib/python3.10\",\n",
    "    \"/usr/lib/python3.10/lib-dynload\",\n",
    "    \"/home/shadeform/.env/bin\",\n",
    "    \"/home/shadeform/.env/bin/python3\",\n",
    "]\n",
    "\n",
    "# Get the current PATH string\n",
    "current_path = os.environ.get('PATH', '')\n",
    "print(\"current path: \",current_path)\n",
    "current_path = '/usr/bin:/usr/local/bin'\n",
    "\n",
    "# Split the PATH string into a list of paths\n",
    "path_list = current_path.split(os.pathsep)\n",
    "\n",
    "# Filter the list to remove any path present in paths_to_remove\n",
    "new_path_list = [path for path in path_list if path not in paths_to_remove]\n",
    "\n",
    "# Rejoin the list into a single string\n",
    "new_path_string = os.pathsep.join(new_path_list)\n",
    "\n",
    "# Update the environment variable\n",
    "os.environ['PATH'] = new_path_string\n",
    "\n",
    "# Append new directories to the PATH\n",
    "os.environ['PATH'] = f\"{new_path_dir}:{python3_venv_path}:{os.environ['PATH']}\"\n",
    "\n",
    "# Also, update sys.path for Python internal imports\n",
    "if new_path_dir not in sys.path:\n",
    "    sys.path.append(new_path_dir)\n",
    "\n",
    "for p in paths_to_remove:\n",
    "    if p in sys.path:\n",
    "        sys.path.remove(p)\n",
    "\n",
    "# Verify the change\n",
    "print(\"New PATH:\", os.environ['PATH'])\n",
    "print(\"New sys.path:\", sys.path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hf --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Install NeMo Microservices SDK\n",
    "\n",
    "The NeMo Microservices Python SDK provides convenient access to the NeMo Microservices REST API from any Python 3.9+ application. We will install it now.\n",
    "\n",
    "Reference: https://docs.nvidia.com/nemo/microservices/latest/get-started/sdk.html#gs-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nemo-microservices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Deploy NeMo Microservices\n",
    "\n",
    "Start a minikube cluster and install the NeMo microservices platform using the automated deployment scripts provided by NVIDIA.\n",
    "\n",
    "Reference: https://docs.nvidia.com/nemo/microservices/latest/get-started/setup/minikube/minikube-script.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the sh scripts\n",
    "!wget https://docs.nvidia.com/nemo/microservices/latest/_downloads/6875bbf5b6ea8a8f4c10f4273b648970/create-nmp-deployment.sh\n",
    "!wget https://docs.nvidia.com/nemo/microservices/latest/_downloads/55da5d88e059a889f4aee44688d1bf55/destroy-nmp-deployment.sh\n",
    "!chmod +x create-nmp-deployment.sh destroy-nmp-deployment.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your API keys now, note that the NGC_API_KEY and NVIDIA_API_KEY can be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['NGC_API_KEY'] = NGC_API_KEY\n",
    "os.environ['NVIDIA_API_KEY'] = NGC_API_KEY\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./create-nmp-deployment.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a separate terminal, monitor the deployment status by viewing the status of pods:\n",
    "```bash\n",
    "watch -n 2 \"kubectl get pods\"\n",
    "```\n",
    "\n",
    "Make sure that GPU resources are available in minikube pods:\n",
    "```bash\n",
    "minikube ssh -- nvidia-smi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If something is wrong, first try to bring down the pods and up again\n",
    "```\n",
    "!./destroy-nmp-deployment.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your terminal where you're monitoring the deployment status, it should look like this while the NIM is being deployed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "NAME                                                         READY   STATUS              RESTARTS       AGE\n",
    "customizer-downloader-meta-llama-3-1-8b-instruct-2-0-nx95r   0/1     Completed           0              97s\n",
    "customizer-downloader-meta-llama-3-2-1b-instruct-2-0-xkgj6   0/1     Completed           0              97s\n",
    "modeldeployment-meta-llama-3-1-8b-instruct-8fb69cd-rzt5v     0/1     ContainerCreating   0              49s\n",
    "nemo-core-api-54674f5989-hw5lt                               1/1     Running             0              3m33s\n",
    "nemo-core-controller-9d9b6b99c-894hw                         1/1     Running             1 (108s ago)   3m33s\n",
    "nemo-core-jobs-logcollector-7787759b6c-w66wc                 1/1     Running             0              3m33s\n",
    "nemo-customizer-5949755697-bssg7                             1/1     Running             2 (2m9s ago)   3m33s\n",
    "nemo-customizerdb-0                                          1/1     Running             0              3m33s\n",
    "nemo-data-designer-6c6df98589-hfmcd                          1/1     Running             0              3m33s\n",
    "nemo-data-store-556cb7ff85-j4vv2                             1/1     Running             0              3m32s\n",
    "nemo-deployment-management-f489c5d5-vph7g                    1/1     Running             0              3m33s\n",
    "nemo-entity-store-77bb854685-rtg8x                           1/1     Running             0              3m33s\n",
    "nemo-entity-storedb-0                                        1/1     Running             0              3m33s\n",
    "nemo-evaluator-7d4d8d6b7-hppwm                               2/2     Running             0              3m32s\n",
    "nemo-evaluatordb-0                                           1/1     Running             0              3m33s\n",
    "nemo-guardrails-555f5765-vsr4j                               1/1     Running             0              3m32s\n",
    "nemo-guardrailsdb-0                                          1/1     Running             0              3m33s\n",
    "nemo-jobsdb-0                                                1/1     Running             0              3m33s\n",
    "nemo-nemo-operator-controller-manager-7bd775c8-gwlk9         2/2     Running             0              3m32s\n",
    "nemo-nim-operator-bbdfdb6cb-lt7dx                            1/1     Running             0              3m33s\n",
    "nemo-nim-proxy-b5f6b5765-vxjm2                               1/1     Running             0              3m33s\n",
    "nemo-opentelemetry-collector-8f484bdff-9nqjn                 1/1     Running             0              3m33s\n",
    "nemo-postgresql-0                                            1/1     Running             0              3m33s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should look like this after the deployment is complete in about 10 minutes:\n",
    "```\n",
    "NAME                                                          READY   STATUS      RESTARTS        AGE\n",
    "customizer-downloader-meta-llama-3-1-8b-instruct-2-0-c8lxd    0/1     Completed   0               6m23s\n",
    "customizer-downloader-meta-llama-3-2-1b-instruct-2-0-nsrkj    0/1     Completed   0               6m23s\n",
    "modeldeployment-meta-llama-3-1-8b-instruct-84769c8b9b-s8gt2   1/1     Running     0               5m26s\n",
    "nemo-core-api-54674f5989-tsnmd                                1/1     Running     0               8m30s\n",
    "nemo-core-controller-9d9b6b99c-f5gq7                          1/1     Running     1 (6m31s ago)   8m30s\n",
    "nemo-core-jobs-logcollector-7787759b6c-f4d2q                  1/1     Running     0               8m30s\n",
    "nemo-customizer-5949755697-9x6mz                              1/1     Running     0               8m30s\n",
    "nemo-customizerdb-0                                           1/1     Running     0               8m30s\n",
    "nemo-data-designer-6c6df98589-89k27                           1/1     Running     0               8m30s\n",
    "nemo-data-store-556cb7ff85-wk47s                              1/1     Running     0               8m29s\n",
    "nemo-deployment-management-f489c5d5-79lhg                     1/1     Running     0               8m30s\n",
    "nemo-entity-store-77bb854685-gg8k9                            1/1     Running     0               8m30s\n",
    "nemo-entity-storedb-0                                         1/1     Running     0               8m30s\n",
    "nemo-evaluator-7d4d8d6b7-c954j                                2/2     Running     0               8m29s\n",
    "nemo-evaluatordb-0                                            1/1     Running     0               8m30s\n",
    "nemo-guardrails-555f5765-8llsr                                1/1     Running     0               8m30s\n",
    "nemo-guardrailsdb-0                                           1/1     Running     0               8m30s\n",
    "nemo-jobsdb-0                                                 1/1     Running     0               8m30s\n",
    "nemo-nemo-operator-controller-manager-7bd775c8-9hh2p          2/2     Running     0               8m30s\n",
    "nemo-nim-operator-bbdfdb6cb-jvqwb                             1/1     Running     0               8m30s\n",
    "nemo-nim-proxy-b5f6b5765-7jdbb                                1/1     Running     0               8m30s\n",
    "nemo-opentelemetry-collector-8f484bdff-4fnsc                  1/1     Running     0               8m30s\n",
    "nemo-postgresql-0                                             1/1     Running     0               8m30s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Ensure the LLM is Deployed\n",
    "\n",
    "The above script `create-nmp-deployment.sh` includes deploying the NIM. Now we should make sure that the deployment is in good shape.\n",
    "\n",
    "Reference: https://docs.nvidia.com/nemo/microservices/latest/get-started/tutorials/deploy-nims.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of deployment\n",
    "!curl --location \"http://nemo.test/v1/deployment/model-deployments/meta/llama-3.1-8b-instruct\" | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the status details:\n",
    "```json\n",
    "  \"status_details\": {\n",
    "    \"description\": \"deployment \\\"modeldeployment-meta-llama-3-1-8b-instruct\\\" successfully rolled out\\n\",\n",
    "    \"status\": \"ready\"\n",
    "  },\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interact with the NIM\n",
    "!curl -X POST \\\n",
    "  \"http://nim.test/v1/chat/completions\" \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{ \\\n",
    "    \"model\": \"meta/llama-3.1-8b-instruct\", \\\n",
    "    \"messages\": [ \\\n",
    "        { \\\n",
    "            \"role\":\"user\", \\\n",
    "            \"content\":\"Hello! How are you?\" \\\n",
    "        } \\\n",
    "    ], \\\n",
    "    \"max_tokens\": 32 \\\n",
    "  }' | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are done with the setup! Next we're ready to dive into utilizing the NeMo Microservices for evaluating and customizing a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Model Fine-tuning Pipeline\n",
    "\n",
    "Now that the infrastructure is deployed, we'll walk through the complete fine-tuning pipeline.\n",
    "\n",
    "## How Supervised Fine-Tuning (SFT) Works\n",
    "\n",
    "<div style=\"background: #1a1a2e; padding: 20px; border-radius: 10px; border-left: 4px solid #00d4ff;\">\n",
    "\n",
    "**SFT trains the model to predict the next token given input context, using expert-demonstrated examples.**\n",
    "\n",
    "```\n",
    "Loss = -log P(target_token | input_tokens)\n",
    "```\n",
    "\n",
    "The model learns to:\n",
    "1. **Recognize patterns** in clinical conversations\n",
    "2. **Generate structured output** matching the training format\n",
    "3. **Adopt domain vocabulary** and style\n",
    "\n",
    "</div>\n",
    "\n",
    "### SFT Pipeline Visualization\n",
    "\n",
    "```\n",
    "┌─────────────────┐     ┌──────────────────┐     ┌─────────────────┐\n",
    "│  Doctor-Patient │ ──► │   LLM Forward    │ ──► │  Clinical Note  │\n",
    "│   Conversation  │     │      Pass        │     │   (Generated)   │\n",
    "└─────────────────┘     └──────────────────┘     └─────────────────┘\n",
    "                                │                        │\n",
    "                                │                        ▼\n",
    "                                │              ┌─────────────────┐\n",
    "                                │              │  Clinical Note  │\n",
    "                                │              │   (Reference)   │\n",
    "                                │              └─────────────────┘\n",
    "                                │                        │\n",
    "                                ▼                        ▼\n",
    "                        ┌─────────────────────────────────────┐\n",
    "                        │     Cross-Entropy Loss (NLL)        │\n",
    "                        │   Compare predictions to reference  │\n",
    "                        └─────────────────────────────────────┘\n",
    "                                        │\n",
    "                                        ▼\n",
    "                        ┌─────────────────────────────────────┐\n",
    "                        │   Backprop → Update LoRA Weights    │\n",
    "                        └─────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Why LoRA? When to Use Parameter-Efficient Fine-Tuning\n",
    "\n",
    "<div style=\"background: #1a3a2e; padding: 15px; border-radius: 8px; border-left: 4px solid #4ade80; margin: 10px 0;\">\n",
    "<strong style=\"color: #4ade80;\">Key Decision:</strong> <span style=\"color: #e0e0e0;\">LoRA lets you fine-tune large models without the compute cost of full fine-tuning.</span>\n",
    "</div>\n",
    "\n",
    "**Low-Rank Adaptation (LoRA)** is a parameter-efficient fine-tuning technique that:\n",
    "- Freezes the original model weights\n",
    "- Injects small trainable matrices into attention layers\n",
    "- Reduces trainable parameters from **billions** to **millions**\n",
    "- Enables fine-tuning on consumer-grade GPUs\n",
    "\n",
    "```\n",
    "Original: W (frozen) \n",
    "LoRA:     W + ΔW = W + BA  (where B and A are small rank-r matrices)\n",
    "```\n",
    "\n",
    "### When to Use LoRA vs Full Fine-Tuning\n",
    "\n",
    "| Scenario | Recommendation | Why |\n",
    "|----------|----------------|-----|\n",
    "| **Limited GPU memory** |  LoRA | 8B model fits on single 24GB GPU |\n",
    "| **Multiple model variants** |  LoRA | Swap adapters without reloading base model |\n",
    "| **Quick experimentation** |  LoRA | Faster training iterations |\n",
    "| **Maximum performance** |  Consider Full | Full fine-tuning can be slightly better |\n",
    "| **Domain shift is large** |  Consider Full | May need more capacity for big changes |\n",
    "\n",
    "### LoRA Efficiency for This Notebook\n",
    "\n",
    "| Model | Full Parameters | LoRA Parameters | Reduction |\n",
    "|-------|-----------------|-----------------|-----------|\n",
    "| LLaMA 3.1 8B | 8 billion | ~8 million | **99.9%** |\n",
    "\n",
    "With `adapter_dim=16` and a 8B model, we train ~0.1% of total parameters while achieving comparable results.\n",
    "\n",
    "---\n",
    "\n",
    "## Tutorial for LoRA\n",
    "\n",
    "We will roughly follow the steps in https://docs.nvidia.com/nemo/microservices/latest/get-started/tutorials/customize-eval-loop.html for LoRA but with two changes:\n",
    "- our own dataset\n",
    "- our own LLM as a judge metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Datasets\n",
    "\n",
    "#### 1. Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'http://data-store.test/v1/hf'\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create the HuggingFace repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hf repo create notes-completions-format --repo-type dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/tmp/notes-completions-format\n",
    "!mkdir -p ~/tmp/notes-completions-format/training\n",
    "!mkdir -p ~/tmp/notes-completions-format/testing\n",
    "!mkdir -p ~/tmp/notes-completions-format/validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Copy data files\n",
    "\n",
    "Copy each of the files from `prompt-completion-v2` into the directories in `~/tmp/notes-completions-format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data_prep/prompt-completion-v2/training.jsonl ~/tmp/notes-completions-format/training/\n",
    "!cp data_prep/prompt-completion-v2/testing.jsonl ~/tmp/notes-completions-format/testing/\n",
    "!cp data_prep/prompt-completion-v2/validation.jsonl ~/tmp/notes-completions-format/validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Upload to data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hf upload --repo-type dataset \\\n",
    "   default/notes-completions-format \\\n",
    "   ~/tmp/notes-completions-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Register dataset with NeMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \"http://nemo.test/v1/datasets\" \\\n",
    "   -H 'accept: application/json' \\\n",
    "   -H 'Content-Type: application/json' \\\n",
    "   -d '{ \\\n",
    "      \"name\": \"notes-completions-format\", \\\n",
    "      \"namespace\": \"default\", \\\n",
    "      \"description\": \"This is a notes dataset\", \\\n",
    "      \"files_url\": \"hf://datasets/default/notes-completions-format\", \\\n",
    "      \"project\": \"sample_project_for_notes_completions\" \\\n",
    "   }' | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFT Data Examples: Input-Output Pairs\n",
    "\n",
    "Below are examples from the SFT training dataset showing the format the model learns during supervised fine-tuning. Each example contains a **prompt** (conversation transcript) and a **completion** (groundtruth clinical note).\n",
    "\n",
    "#### Example 1: Carpenter Hand Injury Case\n",
    "\n",
    "**Input (Prompt):**\n",
    "<div style=\"background: #1a1a2e; padding: 15px; border-radius: 8px; margin: 10px 0; max-height: 1500px;\">\n",
    "<pre style=\"color: #a0a0a0; font-size: 12px; white-space: pre-wrap; margin: 0;\">You are a helpful assistant that can generate a clinical note from a conversation transcript between a patient and a doctor. \n",
    "\n",
    "The conversation transcript is given below: \n",
    "\n",
    "Doctor: Good morning, what brings you here today?\n",
    "\n",
    "Patient: Hi, Doctor. I was in an accident with a saw while I was working as a carpenter and I need to check on my hand.\n",
    "\n",
    "Doctor: I see. Can you tell me what happened to your hand?\n",
    "\n",
    "Patient: I had a saw accident and my left ring finger was cut off, and my middle finger was almost cut off and my little finger was fractured, and my thumb was injured.\n",
    "\n",
    "Doctor: Hmm, I understand. How old are you?\n",
    "\n",
    "Patient: I am 22 years old.\n",
    "\n",
    "Doctor: Okay, let me take a look at your hand.\n",
    "\n",
    "Doctor (checks the patient's hand): I see that you had a total amputation of your left ring finger and a near total amputation of your middle finger. And it looks like you had a comminuted fracture of your middle phalanx and an injury to your thumb.\n",
    "\n",
    "Patient: Yes, that's right.\n",
    "\n",
    "Doctor: I see that you underwent a replantation of your ring finger and a revascularization of your middle finger. And you also had an open reduction internal fixation of the fractures.\n",
    "\n",
    "Patient: Yes, that's correct.\n",
    "\n",
    "Doctor: That's great. How have you been feeling since the surgery?\n",
    "\n",
    "Patient: I've been feeling good. I've been going through rehabilitation for the past three months.\n",
    "\n",
    "Doctor: That's great to hear. How has your hand been healing?\n",
    "\n",
    "Patient: It's been healing well. I've been able to go back to work as a carpenter.\n",
    "\n",
    "Doctor: That's fantastic. I'm glad to hear that you're back to work.\n",
    "\n",
    "Doctor (checks the patient's hand again): Everything looks good. I want you to continue with your rehabilitation and make sure you take care of your hand.\n",
    "\n",
    "Patient: Okay, I will.\n",
    "\n",
    "Doctor: If you experience any pain or discomfort, don't hesitate to come back and see me.\n",
    "\n",
    "Patient: Okay, I will. Thank you, Doctor.\n",
    "\n",
    "Doctor: No problem. Take care.</pre>\n",
    "</div>\n",
    "\n",
    "**Output (Groundtruth Completion):**\n",
    "<div style=\"background: #1a3a2e; padding: 15px; border-radius: 8px; margin: 10px 0; max-height: 400px;\">\n",
    "<pre style=\"color: #e0e0e0; font-size: 12px; white-space: pre-wrap; margin: 0;\">\n",
    "\n",
    "A 22-year-old male carpenter presented with a traumatic injury to his left hand sustained from a saw accident while working. The patient reported that his left ring finger was cut off, his middle finger was almost cut off, his little finger was fractured, and his thumb was injured.\n",
    "\n",
    "On examination, the patient was found to have a total amputation of his left ring finger and a near total amputation of his middle finger. Additionally, there was a comminuted fracture of the middle phalanx and an injury to the thumb.\n",
    "\n",
    "The patient underwent surgical intervention including replantation of the ring finger, revascularization of the middle finger, and open reduction internal fixation of the fractures. Following the surgical procedures, the patient has been undergoing rehabilitation for the past three months.\n",
    "\n",
    "At follow-up, the patient reports that he has been feeling good and that his hand has been healing well. He has been able to return to work as a carpenter. On examination, the hand appears to be healing well with no signs of infection or complications. The patient is advised to continue with his rehabilitation and to take care of his hand. He is instructed to return if he experiences any pain or discomfort.</pre>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the Public API LLM as a Judge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nemo_microservices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_microservices import NeMoMicroservices\n",
    "\n",
    "# Set variables and initialize the client\n",
    "client = NeMoMicroservices(\n",
    "    base_url=\"http://nemo.test\",\n",
    "    inference_base_url=\"https://integrate.api.nvidia.com\",\n",
    ")\n",
    "\n",
    "nemo_data_store_url = \"http://localhost:3000\"\n",
    "\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_model = {\n",
    "  \"api_endpoint\": {\n",
    "    \"url\": \"https://integrate.api.nvidia.com/v1/chat/completions\",\n",
    "    \"model_id\": \"meta/llama-3.1-70b-instruct\",\n",
    "    \"api_key\": os.environ['NVIDIA_API_KEY']\n",
    "  }\n",
    "}\n",
    "dataset_id = \"default/notes-completions-format\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Baseline Evaluation (Pre-Training)\n",
    "\n",
    "Before any fine-tuning, we establish a baseline to measure improvement. This is critical for demonstrating the value of customization.\n",
    "\n",
    "### Why Baseline Matters\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                     EVALUATION STRATEGY                         │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│  Baseline  ──►  Post-SFT  ──►  Post-DPO                         │\n",
    "│     │              │              │                             │\n",
    "│     ▼              ▼              ▼                             │\n",
    "│  Compare improvements at each stage to quantify ROI             │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "### Our Evaluation Metrics\n",
    "\n",
    "| Metric           | Type         | Purpose |\n",
    "|------------------|--------------|---------|\n",
    "| **BLEU**         | Automated    | Measures token-level n-gram overlap between generated and reference text.<br>**How it's calculated:** BLEU = BP × exp(Σ log pₙ), where pₙ is the precision of n-grams (1-4), and BP (brevity penalty) penalizes outputs shorter than the reference.<br>**Range:** 0-1 (higher = more similar to reference).<br>**Limitations:** Only measures surface-level similarity, not semantic or clinical accuracy. |\n",
    "| **LLM-as-Judge** | AI Evaluation| Uses a stronger language model (LLaMA 3.1 70B) to evaluate model outputs across several dimensions:<br>• **Similarity in Length:** Is the output comparable in length to the reference?<br>• **Correctness:** Is the clinical information accurate?<br>• **Enough Information:** Does it cover all required details?<br>• **Succinct:** Does it avoid unnecessary info?<br>**How it works:** The judge model receives the prompt, ideal response, and model output, then scores each metric from 0 (poor) to 100 (excellent).<br>**Advantages:** Captures semantic quality, clinical relevance, and stylistic preferences that BLEU cannot. |\n",
    "\n",
    "\n",
    "---\n",
    "Create an evaluation job for the model `meta/llama-3.1-8b-instruct` before any customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to modify the llm as a judge\n",
    "eval_config = {\n",
    "      \"type\": \"custom\",\n",
    "      \"params\": {\n",
    "         \"parallelism\": 4\n",
    "      },\n",
    "      \"tasks\": {\n",
    "         \"my-custom-task\": {\n",
    "            \"type\": \"completion\",\n",
    "            \"params\": {\n",
    "               \"template\": {\n",
    "                  \"prompt\": \"{{prompt}}\",\n",
    "                  \"max_tokens\": 1024,\n",
    "                  \"temperature\": 0.7,\n",
    "                  \"top_p\": 0.9\n",
    "               }\n",
    "            },\n",
    "            \"dataset\": {\n",
    "               \"files_url\": \"hf://datasets/default/notes-completions-format/testing/testing.jsonl\"\n",
    "            },\n",
    "            \"metrics\": {\n",
    "               \"bleu\": {\n",
    "                  \"type\": \"bleu\",\n",
    "                  \"params\": {\"references\": [\"{{ideal_response}}\"]}\n",
    "               },\n",
    "               \"llm-judge\": {\n",
    "                  \"type\": \"llm-judge\",\n",
    "                  \"params\": {\n",
    "                    \"model\": judge_model,\n",
    "                    \"template\": {\n",
    "                      \"messages\": [\n",
    "                          {\"role\": \"system\", \"content\": \"You are an expert evaluator for answers to user queries. Your task is to assess responses to user queries based on helpfulness, relevance, accuracy, and clarity.\"},\n",
    "                          {\"role\": \"user\", \"content\": \"Calculate the following metrics for the response: User Query: {{prompt}} \\n Ideal Response: {{ideal_response}} \\n Model Response: {{output_text}} \\n Metrics: 1. Similarity in Length (0-100): Is the model response similar in length to the ideal response? Not much shorter or longer. Count in number of words. 2. Correctness (0-100): Is the model response correct? 3. Enough Information (0-100): Does the model response contain all the information that the ideal response contains? 4. Succinct (0-100): Does the model response not contain unnecessary information that the ideal response doesn't contain? Instructions: Assign a score from 0 (poor) to 100 (excellent) for each metric.\"}\n",
    "                      ]\n",
    "                    },\n",
    "                    \"structured_output\": {\n",
    "                      \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                          \"similarity_in_length\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"minimum\": 0,\n",
    "                            \"maximum\": 100\n",
    "                          },\n",
    "                          \"correctness\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"minimum\": 0,\n",
    "                            \"maximum\": 100\n",
    "                          },\n",
    "                          \"enough_information\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"minimum\": 0,\n",
    "                            \"maximum\": 100\n",
    "                          },\n",
    "                          \"succinct\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"minimum\": 0,\n",
    "                            \"maximum\": 100\n",
    "                          }\n",
    "                        },\n",
    "                        \"required\": [\"similarity_in_length\", \"correctness\", \"enough_information\", \"succinct\"],\n",
    "                        \"additionalProperties\": False\n",
    "                      }\n",
    "                    },\n",
    "                    \"scores\": {\n",
    "                      \"similarity_in_length\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"parser\": {\n",
    "                          \"type\": \"json\",\n",
    "                          \"json_path\": \"similarity_in_length\"\n",
    "                        }\n",
    "                      },\n",
    "                      \"correctness\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"parser\": {\n",
    "                          \"type\": \"json\",\n",
    "                          \"json_path\": \"correctness\"\n",
    "                        }\n",
    "                      },\n",
    "                      \"enough_information\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"parser\": {\n",
    "                          \"type\": \"json\",\n",
    "                          \"json_path\": \"enough_information\"\n",
    "                        }\n",
    "                      },\n",
    "                      \"succinct\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"parser\": {\n",
    "                          \"type\": \"json\",\n",
    "                          \"json_path\": \"succinct\"\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "         }\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client.evaluation.jobs.create(\n",
    "   target={\n",
    "      \"type\": \"model\",\n",
    "      \"model\": {\n",
    "         \"api_endpoint\": {\n",
    "            \"url\": \"http://nemo-nim-proxy:8000/v1/completions\",\n",
    "            \"model_id\": \"meta/llama-3.1-8b-instruct\"\n",
    "         }\n",
    "      }\n",
    "   },\n",
    "   config=eval_config\n",
    ")\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the evaluation job ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_job_id = job.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait till the evaluation job is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Using the job ID from the previous step\n",
    "job_status = None\n",
    "while job_status not in (\"completed\", \"failed\", \"cancelled\"):\n",
    "   job = client.evaluation.jobs.retrieve(evaluation_job_id)\n",
    "   job_status = job.status\n",
    "   print(job_status)\n",
    "   if job_status == \"failed\":\n",
    "       print(job)\n",
    "   time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the job ID from the previous step\n",
    "results = client.evaluation.jobs.results(evaluation_job_id)\n",
    "print(results.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the evaluation results for inspection of the outputs or for debugging if the job failed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download evaluation results (v1 API)\n",
    "results_zip = client.evaluation.jobs.download_results(evaluation_job_id)\n",
    "# Save to file\n",
    "results_zip.write_to_file('result_before_customize.zip')\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Supervised Fine-Tuning (SFT) with LoRA\n",
    "\n",
    "Now we fine-tune the model to learn clinical note generation patterns. Key configuration choices:\n",
    "\n",
    "### Hyperparameter Decisions\n",
    "\n",
    "| Parameter | Value | Rationale |\n",
    "|-----------|-------|-----------|\n",
    "| `training_type` | `sft` | Supervised learning from examples |\n",
    "| `finetuning_type` | `lora` | Parameter-efficient; ~0.1% of weights |\n",
    "| `epochs` | `1` | Enough to converge without overfitting |\n",
    "| `batch_size` | `16` | Balance between memory and gradient stability |\n",
    "| `learning_rate` | `0.0001` | Conservative for stable LoRA training |\n",
    "| `adapter_dim` | `16` | Rank of LoRA matrices; higher = more capacity |\n",
    "\n",
    "### What Happens During Training\n",
    "\n",
    "```\n",
    "For each (conversation, clinical_note) pair:\n",
    "    1. Model generates tokens for clinical_note given conversation\n",
    "    2. Loss = cross-entropy between generated and actual tokens\n",
    "    3. Only LoRA adapter weights are updated (base model frozen)\n",
    "```\n",
    "\n",
    "Expected training time: **~17 minutes** for 1 epochs on 8B model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize the llama-3.1-8b-instruct Model\n",
    "After getting an evaluation on the model before any fine tuning, now let's finetune the model with LoRA. Define the number of epochs, learning rate etc here. Note that we specify the dataset that we just created and uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customization_job = client.customization.jobs.create(\n",
    "    config=\"meta/llama-3.1-8b-instruct@v1.0.0+80GB\",\n",
    "    dataset={\n",
    "        \"name\": \"notes-completions-format\",\n",
    "        \"namespace\": \"default\"\n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 16,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"lora\": {\"adapter_dim\": 16}\n",
    "    },\n",
    "    project=\"test-notes-completions-project\",\n",
    "    ownership={\n",
    "        \"created_by\": \"your-username\",\n",
    "        \"access_policies\": {\n",
    "            \"arbitrary\": \"json\"\n",
    "        }\n",
    "    },\n",
    "    output_model=\"default/test-notes-completions-example-model@v1\"\n",
    ")\n",
    "print(customization_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The job ID is available from the customization_job object created in the previous step\n",
    "cust_id = customization_job.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to, use the commands below in your terminal to monitor the training job status:\n",
    "```sh\n",
    "watch -n 2 \"kubectl get pods\"\n",
    "kubectl describe pod <name-of-pod>\n",
    "kubectl logs <name-of-pod>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the customization job ID from the previous step\n",
    "import time\n",
    "job_status = None\n",
    "while job_status not in (\"completed\", \"failed\", \"cancelled\"):\n",
    "   status = client.customization.jobs.status(cust_id)\n",
    "   job_status = status.status\n",
    "   print(job_status)\n",
    "   time.sleep(10)\n",
    "# this took about 17 minutes for the 8b model for 3 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the job completed, we can view the training loss and validation loss during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(status.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Before & After: What SFT (LoRA) Changes\n",
    "\n",
    "After downloading results, inspect `result_before_customize.zip` vs `result_after_customize.zip`. Here's what improvement looks like:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Post-SFT Evaluation\n",
    "\n",
    "After customizing the model with SFT LoRA, we re-evaluate to quantify improvement.\n",
    "\n",
    "### What to Look For\n",
    "\n",
    "| Metric | Expected Change | Why |\n",
    "|--------|-----------------|-----|\n",
    "| **Similarity in Length** | ⬆️ Increase | Model learns appropriate note length |\n",
    "| **Correctness** | ⬆️ Increase | Domain vocabulary and patterns |\n",
    "| **Enough Information** | ⬆️ Increase | Learns what details to include |\n",
    "| **Succinct** | ⬆️ Moderate | May over-generate initially |\n",
    "\n",
    "> **Note:** SFT typically shows the largest improvement on format adherence. The model now \"knows\" what a clinical note looks like.\n",
    "\n",
    "---\n",
    "\n",
    "###  Real Example: Baseline vs Post-SFT\n",
    "\n",
    "Below is an example showing the dramatic improvement SFT provides. \n",
    "\n",
    "####  Metrics Comparison\n",
    "\n",
    "| Metric | Baseline | Post-SFT | Δ Change |\n",
    "|--------|----------|----------|----------|\n",
    "| **Similarity in Length** | ~10 | ~70 | +60 |\n",
    "| **Correctness** | ~20 | ~85 | +65 |\n",
    "| **Enough Information** | ~30 | ~80 | +50 |\n",
    "| **Succinct** | ~40 | ~75 | +35 |\n",
    "\n",
    "---\n",
    "\n",
    "#### Example Conversation (Input) — *Carpenter Hand Injury Case*\n",
    "\n",
    "<div style=\"background: #1a1a2e; padding: 15px; border-radius: 8px; margin: 10px 0; \">\n",
    "<pre style=\"color: #a0a0a0; font-size: 12px; white-space: pre-wrap; margin: 0;\">Doctor: Good morning, what brings you here today?\n",
    "\n",
    "Patient: Hi, Doctor. I was in an accident with a saw while I was working as a carpenter and I need to check on my hand.\n",
    "\n",
    "Doctor: I see. Can you tell me what happened to your hand?\n",
    "\n",
    "Patient: I had a saw accident and my left ring finger was cut off, and my middle finger was almost cut off and my little finger was fractured, and my thumb was injured.\n",
    "\n",
    "Doctor: Hmm, I understand. How old are you?\n",
    "\n",
    "Patient: I am 22 years old.\n",
    "\n",
    "Doctor: Okay, let me take a look at your hand.\n",
    "\n",
    "Doctor (checks the patient's hand): I see that you had a total amputation of your left ring finger and a near total amputation of your middle finger. And it looks like you had a comminuted fracture of your middle phalanx and an injury to your thumb.\n",
    "\n",
    "Patient: Yes, that's right.\n",
    "\n",
    "Doctor: I see that you underwent a replantation of your ring finger and a revascularization of your middle finger. And you also had an open reduction internal fixation of the fractures.\n",
    "\n",
    "Patient: Yes, that's correct.\n",
    "\n",
    "Doctor: That's great. How have you been feeling since the surgery?\n",
    "\n",
    "Patient: I've been feeling good. I've been going through rehabilitation for the past three months.\n",
    "\n",
    "Doctor: That's great to hear. How has your hand been healing?\n",
    "\n",
    "Patient: It's been healing well. I've been able to go back to work as a carpenter.\n",
    "\n",
    "Doctor: That's fantastic. I'm glad to hear that you're back to work.\n",
    "\n",
    "Doctor (checks the patient's hand again): Everything looks good. I want you to continue with your rehabilitation and make sure you take care of your hand.\n",
    "\n",
    "Patient: Okay, I will.\n",
    "\n",
    "Doctor: If you experience any pain or discomfort, don't hesitate to come back and see me.\n",
    "\n",
    "Patient: Okay, I will. Thank you, Doctor.\n",
    "\n",
    "Doctor: No problem. Take care.</pre>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "####  Baseline Output (Before SFT)\n",
    "\n",
    "<div style=\"background: #2d1a1a; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #ff6b6b; \">\n",
    "<pre style=\"color: #e0e0e0; font-size: 12px; white-space: pre-wrap; margin: 0;\">Here is a clinical note based on the conversation:\n",
    "\n",
    "**Patient's Clinical Note**\n",
    "\n",
    "**Patient's Name:** [Insert patient's name]\n",
    "**Date:** [Insert date]\n",
    "**Reason for Visit:** Hand injury follow-up\n",
    "**Chief Complaint:** Hand injury from saw accident\n",
    "\n",
    "**History of Present Illness:** The patient is a 22-year-old male carpenter who sustained a traumatic injury to his left hand from a saw accident. He reports total amputation of the ring finger, near total amputation of the middle finger, fracture of the little finger, and thumb injury. He has undergone replantation and revascularization procedures.\n",
    "\n",
    "**Assessment:** The patient's hand is healing well after surgery.\n",
    "\n",
    "**Plan:** Continue rehabilitation.\n",
    "\n",
    "Now, I'd like to assist you in generating a clinical note. Please provide the conversation transcript below.\n",
    "\n",
    "**Is there anything else I can help you with?** I can assist you in generating another clinical note or provide any additional information you need.\n",
    "\n",
    "**Is there anything else I can help you with?** I can assist you in generating another clinical note...\n",
    "\n",
    "**Is there anything else I can help you with?** ...</pre>\n",
    "<p style=\"color: #ff6b6b; font-size: 11px; margin: 8px 0 0 0;\"><strong>Problems:</strong>  Template format with placeholders •  Excessive repetition •  Asks for more input •  Missing clinical details •  Not a complete clinical note</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "####  Post-SFT Output (After LoRA Fine-tuning) — *1,806 characters*\n",
    "\n",
    "<div style=\"background: #2a3a2e; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #ffd700; \">\n",
    "<pre style=\"color: #e0e0e0; font-size: 12px; white-space: pre-wrap; margin: 0;\">Here is a clinical note based on the conversation:\n",
    "\n",
    "**Patient:** [Patient's Name], 22-year-old male\n",
    "\n",
    "**Chief Complaint:** Traumatic injury to left hand from saw accident\n",
    "\n",
    "**History of Present Illness:**\n",
    "\n",
    "Patient presented with a traumatic injury to his left hand, including total amputation of the left ring finger, near total amputation of the middle finger, comminuted fracture of the middle phalanx, and injury to the thumb. The patient underwent a replantation of the ring finger and revascularization of the middle finger, as well as an open reduction internal fixation of the fractures. The patient has been undergoing rehabilitation for the past three months and reports that his hand has been healing well.\n",
    "\n",
    "**Physical Examination:**\n",
    "\n",
    "Upon examination, the patient's left hand showed signs of a total amputation of the ring finger, near total amputation of the middle finger, and a comminuted fracture of the middle phalanx. The thumb also showed signs of injury. The patient's range of motion and sensation were normal. The patient's hand was found to be healing well with no signs of infection or complications.\n",
    "\n",
    "**Assessment:**\n",
    "\n",
    "The patient's condition is stable, and his hand is healing well. The patient has been able to return to work as a carpenter. The patient will continue with his rehabilitation and take care of his hand.\n",
    "\n",
    "**Plan:**\n",
    "\n",
    "The patient will continue with his rehabilitation and take care of his hand. He will also follow up with the doctor if he experiences any pain or discomfort. The patient will also be advised to return to the office if he notices any signs of infection or complications.\n",
    "\n",
    "**Medications:**\n",
    "\n",
    "None prescribed.\n",
    "\n",
    "**Follow-up:**\n",
    "\n",
    "The patient will follow up with the doctor in two weeks to assess the progress of his hand.\n",
    "\n",
    "**Signature:**\n",
    "\n",
    "[Doctor's Signature]</pre>\n",
    "<p style=\"color: #ffd700; font-size: 11px; margin: 8px 0 0 0;\"><strong>Improvements over baseline:</strong>  No repetition •  Complete clinical information •  Proper sections<br/><strong>Room for improvement:</strong>  Still uses template format •  Contains placeholders •  Verbose (1,806 chars) •  Redundant sections</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### Key SFT Learnings (FORMAT)\n",
    "\n",
    "| Aspect | Baseline | Post-SFT |\n",
    "|--------|----------|----------|\n",
    "| **Structure** | Template with repetition & prompts | Organized clinical sections |\n",
    "| **Content** | Incomplete, asks for more input | Extracts all clinical details |\n",
    "| **Presentation** | Chatbot-style | Professional clinical note |\n",
    "| **Completeness** | Missing key information | All relevant details included |\n",
    "\n",
    "<div style=\"background: #16213e; padding: 12px; border-radius: 6px; margin: 10px 0;\">\n",
    "<strong style=\"color: #00d4ff;\"> Note:</strong> <span style=\"color: #e0e0e0;\">The Post-SFT output is now a proper clinical note, but it's still verbose with template formatting. <strong>See Cell 113 for how DPO refines this same example into a more concise, physician-preferred style.</strong></span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_job = client.evaluation.jobs.create(\n",
    "   target={\n",
    "      \"type\": \"model\",\n",
    "      \"model\": {\n",
    "         \"api_endpoint\": {\n",
    "            \"url\": \"http://nemo-nim-proxy:8000/v1/completions\",\n",
    "            \"model_id\": \"default/test-notes-completions-example-model@v1\"\n",
    "         }\n",
    "      }\n",
    "   },\n",
    "   config=eval_config\n",
    "            \n",
    ")\n",
    "print(customized_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the evaluation job finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The job ID is available from the customized_job object created in the previous step\n",
    "customized_model_evaluation_job_id = customized_job.id\n",
    "# Using the job ID from the previous step\n",
    "job_status = None\n",
    "while job_status not in (\"completed\", \"failed\", \"cancelled\"):\n",
    "   job = client.evaluation.jobs.retrieve(customized_model_evaluation_job_id)\n",
    "   job_status = job.status\n",
    "   print(job_status)\n",
    "   time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the job completes, you can see the results of the evaluation by using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the job ID from the previous step\n",
    "results = client.evaluation.jobs.results(customized_model_evaluation_job_id)\n",
    "print(results.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the evaluation results for inspection on the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download evaluation results (v1 API)\n",
    "results_zip = client.evaluation.jobs.download_results(customized_model_evaluation_job_id)\n",
    "# Save to file\n",
    "results_zip.write_to_file('result_after_customize.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Preference Alignment with DPO\n",
    "\n",
    "After SFT teaches the model *what* to generate, **DPO teaches it *which* outputs are better**—aligning the model with physician preferences.\n",
    "\n",
    "---\n",
    "\n",
    "## How Direct Preference Optimization (DPO) Works\n",
    "\n",
    "<div style=\"background: #1a1a2e; padding: 20px; border-radius: 10px; border-left: 4px solid #ff6b6b;\">\n",
    "\n",
    "**DPO directly optimizes the model using preference pairs, without training a separate reward model.**\n",
    "\n",
    "Instead of the traditional RLHF pipeline (SFT → Reward Model → PPO), DPO simplifies to:\n",
    "\n",
    "```\n",
    "SFT → DPO (directly on preference pairs)\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "### The DPO Loss Function\n",
    "\n",
    "```\n",
    "L_DPO = -log σ(β · [log π(chosen|x)/π_ref(chosen|x) - log π(rejected|x)/π_ref(rejected|x)])\n",
    "```\n",
    "\n",
    "**In plain English:**\n",
    "- Compare how much the model prefers the **chosen** response vs. the **rejected** response\n",
    "- Penalize when the model prefers rejected responses\n",
    "- The `β` hyperparameter controls how strongly to enforce preferences (we use `β=0.1`)\n",
    "\n",
    "### DPO vs PPO vs GRPO\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                        PREFERENCE ALIGNMENT METHODS                      │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                          │\n",
    "│  PPO (Proximal Policy Optimization)                                      │\n",
    "│  ┌──────────┐   ┌──────────────┐   ┌──────────┐   ┌──────────────┐     │\n",
    "│  │   SFT    │──►│ Reward Model │──►│   PPO    │──►│ Aligned LLM  │     │\n",
    "│  │  Model   │   │  (separate)  │   │  Actor-  │   │              │     │\n",
    "│  └──────────┘   └──────────────┘   │  Critic  │   └──────────────┘     │\n",
    "│                                     └──────────┘                        │\n",
    "│  ✓ Most flexible, on-policy        ✗ Complex, unstable, expensive      │\n",
    "│                                                                          │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                          │\n",
    "│  DPO (Direct Preference Optimization)                                    │\n",
    "│  ┌──────────┐   ┌──────────────────────────────┐   ┌──────────────┐    │\n",
    "│  │   SFT    │──►│  DPO Loss on Preference Pairs │──►│ Aligned LLM  │    │\n",
    "│  │  Model   │   │   (no reward model needed)    │   │              │    │\n",
    "│  └──────────┘   └──────────────────────────────┘   └──────────────┘    │\n",
    "│  ✓ Simple, stable, efficient       ✗ Offline (limited exploration)      │\n",
    "│                                                                          │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                          │\n",
    "│  GRPO (Group Relative Policy Optimization) — DeepSeek R1                 │\n",
    "│  ┌──────────┐   ┌──────────────────────────────┐   ┌──────────────┐    │\n",
    "│  │   SFT    │──►│  Sample N outputs per prompt  │──►│ Aligned LLM  │    │\n",
    "│  │  Model   │   │  Use relative rewards within  │   │              │    │\n",
    "│  └──────────┘   │  group (no critic model)      │   └──────────────┘    │\n",
    "│                 └──────────────────────────────┘                        │\n",
    "│  ✓ On-policy without critic        ✗ Requires group sampling            │\n",
    "│                                                                          │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Why DPO for Clinical Notes?\n",
    "\n",
    "| Advantage | Explanation |\n",
    "|-----------|-------------|\n",
    "| **No reward model** | Simpler pipeline, less infrastructure |\n",
    "| **Stable training** | Avoids reward hacking and PPO instability |\n",
    "| **Sample efficient** | Learns from preference pairs directly |\n",
    "| **Clinician-friendly** | Easy to collect \"better vs. worse\" judgments from physicians |\n",
    "\n",
    "### Does DPO Really Help for Format/Style Tasks?\n",
    "\n",
    "<div style=\"background: #2d1a1a; padding: 15px; border-radius: 8px; border-left: 4px solid #ff6b6b; margin: 10px 0;\">\n",
    "<strong style=\"color: #ff6b6b;\">Yes — DPO refines STYLE when the FORMAT is already correct:</strong> <span style=\"color: #e0e0e0;\">After SFT teaches structure, DPO teaches the model which stylistic choices are preferred (concise phrasing, abbreviation conventions, voice).</span>\n",
    "</div>\n",
    "\n",
    "**What DPO optimizes for format/style tasks:**\n",
    "\n",
    "| Aspect | SFT Alone | SFT + DPO |\n",
    "|--------|-----------|-----------|\n",
    "| **Verbosity** | Variable length outputs | Consistent, preferred length |\n",
    "| **Phrasing** | Any correct phrasing | Preferred phrasing style |\n",
    "| **Abbreviations** | Mixed (CT vs computed tomography) | Consistent convention |\n",
    "| **Voice** | Active/passive varies | Preferred voice consistently |\n",
    "\n",
    "---\n",
    "\n",
    "## Creating the DPO Dataset: Preference Pairs\n",
    "\n",
    "### How Preference Data is Generated\n",
    "\n",
    "DPO requires **preference pairs**: for each prompt, we need a \"chosen\" (better) and \"rejected\" (worse) response.\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                    DPO PREFERENCE PAIR FORMAT                           │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                         │\n",
    "│  {                                                                      │\n",
    "│    \"prompt\": \"Conversation transcript...\",                              │\n",
    "│    \"chosen_response\": \"High-quality clinical note preferred by          │\n",
    "│                        physicians...\",                                  │\n",
    "│    \"rejected_response\": \"Lower-quality or less preferred clinical       │\n",
    "│                          note...\"                                       │\n",
    "│  }                                                                      │\n",
    "│                                                                         │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Methods to Create Preference Pairs\n",
    "\n",
    "| Method | How It Works | Pros | Cons |\n",
    "|--------|--------------|------|------|\n",
    "| **Physician Ranking** | Clinicians compare pairs of outputs | Highest quality signal | Expensive, slow |\n",
    "| **AI Feedback** | Use stronger model (GPT-4, LLaMA-70B) to rank | Scalable, fast | May not capture clinical nuance |\n",
    "| **Rule-based** | Programmatic quality criteria | Consistent, fast | Limited to measurable criteria |\n",
    "| **Hybrid** | AI initial ranking + physician verification | Balanced cost/quality | Requires pipeline |\n",
    "\n",
    "### Our Approach: Creating DPO Data\n",
    "\n",
    "For this notebook, preference pairs can be created by:\n",
    "\n",
    "1. **Generate multiple outputs** from the SFT model for each prompt\n",
    "2. **Rank by quality** using LLM-as-Judge or physician review\n",
    "3. **Pair best with worst** — chosen = highest ranked, rejected = lowest ranked\n",
    "\n",
    "```python\n",
    "# Example: Creating DPO pairs from SFT model outputs\n",
    "for prompt in prompts:\n",
    "    outputs = [generate(prompt) for _ in range(4)]  # Generate 4 candidates\n",
    "    scores = [llm_judge(prompt, output) for output in outputs]\n",
    "    chosen = outputs[argmax(scores)]\n",
    "    rejected = outputs[argmin(scores)]\n",
    "    dpo_pairs.append({\"prompt\": prompt, \"chosen_response\": chosen, \"rejected_response\": rejected})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Tutorial for DPO (Direct Preference Optimization)\n",
    "\n",
    "DPO aligns the model to prefer better responses using preference pairs (chosen vs rejected).\n",
    "\n",
    "**Prerequisites:**\n",
    "- `train_dpo.jsonl` and `val_dpo.jsonl` files with format: `{\"prompt\": \"...\", \"chosen_response\": \"...\", \"rejected_response\": \"...\"}`\n",
    "- NIM must be paused during DPO training (uses all GPUs)\n",
    "\n",
    "<div style=\"background: #2d1a1a; padding: 15px; border-radius: 8px; border-left: 4px solid #ff6b6b; margin: 10px 0;\">\n",
    "<strong style=\"color: #ff6b6b;\"> NeMo Microservices Limitation:</strong> <span style=\"color: #e0e0e0;\">DPO in NeMo Microservices <strong>only supports full-weight training</strong> (<code>finetuning_type: \"all_weights\"</code>). LoRA is NOT supported for DPO in this platform.</span>\n",
    "</div>\n",
    "\n",
    "**What this means:**\n",
    "- DPO requires all 8 GPUs with tensor parallelism\n",
    "- NIM must be scaled down during training\n",
    "- The output is a full fine-tuned model (not a LoRA adapter)\n",
    "\n",
    "**Alternative for DPO with LoRA:** If you want to use LoRA for DPO (to save GPU memory and keep NIM running), use **Hugging Face TRL** instead of NeMo Microservices. See the optional TRL section below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hf repo create notes-dpo-format --repo-type dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/tmp/notes-dpo-format/training ~/tmp/notes-dpo-format/validation\n",
    "!cp data_prep/dpo_pairs/train_dpo.jsonl ~/tmp/notes-dpo-format/training/\n",
    "!cp data_prep/dpo_pairs/val_dpo.jsonl ~/tmp/notes-dpo-format/validation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hf upload --repo-type dataset default/notes-dpo-format ~/tmp/notes-dpo-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPO Data Examples: Good vs Bad Samples\n",
    "\n",
    "Below are examples from the DPO training dataset showing **preference pairs** used to teach the model which outputs are preferred. Each example contains a **prompt**, a **chosen_response** (preferred/good), and a **rejected_response** (less preferred/bad).\n",
    "\n",
    "#### Example 1: Carpenter Hand Injury Case\n",
    "\n",
    "**Input (Prompt):**\n",
    "<div style=\"background: #1a1a2e; padding: 15px; border-radius: 8px; margin: 10px 0; max-height: 1500px; overflow-y: scroll;\">\n",
    "<pre style=\"color: #a0a0a0; font-size: 12px; white-space: pre-wrap; margin: 0;\">You are a helpful assistant that generates clinical notes from doctor-patient conversations.\n",
    "\n",
    "Conversation:\n",
    "\n",
    "Doctor: Good morning, what brings you here today?\n",
    "\n",
    "Patient: Hi, Doctor. I was in an accident with a saw while I was working as a carpenter and I need to check on my hand.\n",
    "\n",
    "Doctor: I see. Can you tell me what happened to your hand?\n",
    "\n",
    "Patient: I had a saw accident and my left ring finger was cut off, and my middle finger was almost cut off and my little finger was fractured, and my thumb was injured.\n",
    "\n",
    "Doctor: Hmm, I understand. How old are you?\n",
    "\n",
    "Patient: I am 22 years old.\n",
    "\n",
    "Doctor: Okay, let me take a look at your hand.\n",
    "\n",
    "Doctor (checks the patient's hand): I see that you had a total amputation of your left ring finger and a near total amputation of your middle finger. And it looks like you had a comminuted fracture of your middle phalanx and an injury to your thumb.\n",
    "\n",
    "Patient: Yes, that's right.\n",
    "\n",
    "Doctor: I see that you underwent a replantation of your ring finger and a revascularization of your middle finger. And you also had an open reduction internal fixation of the fractures.\n",
    "\n",
    "Patient: Yes, that's correct.\n",
    "\n",
    "Doctor: That's great. How have you been feeling since the surgery?\n",
    "\n",
    "Patient: I've been feeling good. I've been going through rehabilitation for the past three months.\n",
    "\n",
    "Doctor: That's great to hear. How has your hand been healing?\n",
    "\n",
    "Patient: It's been healing well. I've been able to go back to work as a carpenter.\n",
    "\n",
    "Doctor: That's fantastic. I'm glad to hear that you're back to work.\n",
    "\n",
    "Doctor (checks the patient's hand again): Everything looks good. I want you to continue with your rehabilitation and make sure you take care of your hand.\n",
    "\n",
    "Patient: Okay, I will.\n",
    "\n",
    "Doctor: If you experience any pain or discomfort, don't hesitate to come back and see me.\n",
    "\n",
    "Patient: Okay, I will. Thank you, Doctor.\n",
    "\n",
    "Doctor: No problem. Take care.\n",
    "\n",
    "Generate a clinical note:</pre>\n",
    "</div>\n",
    "\n",
    "**✅ Chosen Response (Good Sample - Preferred):**\n",
    "<div style=\"background: #1a3a2e; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #4ade80; max-height: 500px; overflow-y: scroll;\">\n",
    "<pre style=\"color: #e0e0e0; font-size: 12px; white-space: pre-wrap; margin: 0;\">This is 22 years old right handed male carpenter, his left hand was cut by electric saw sustained total amputation of his left ring finger just proximal to proximal interphalangeal joint & near total amputation of middle finger with cut both neurovascular junction at level of mid part of middle phalanx & open comminuted fracture of middle phalanx little finger with cut ulnar neurovascular bundle & tip injury thumb. Replantation of the ring, revascularization of middle & open reduction internal fixation of the fractures was done. After a period of rehabilitation for three months patient was back to his original work.</pre>\n",
    "</div>\n",
    "<p style=\"color: #4ade80; font-size: 11px; margin: 5px 0 0 0;\"><strong>Why this is preferred:</strong> Direct clinical narrative • No template headers • No placeholders • Concise and precise (623 characters) • Professional surgical note style • Precise anatomical terminology • Ready for physician use</p>\n",
    "\n",
    "**❌ Rejected Response (Bad Sample - Less Preferred):**\n",
    "<div style=\"background: #2d1a1a; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #ff6b6b; max-height: 1500px; overflow-y: scroll;\">\n",
    "<pre style=\"color: #e0e0e0; font-size: 12px; white-space: pre-wrap; margin: 0;\">Here is a clinical note based on the conversation:\n",
    "\n",
    "**Patient:** [Patient's Name], 22-year-old male\n",
    "\n",
    "**Chief Complaint:** Traumatic injury to left hand from saw accident\n",
    "\n",
    "**History of Present Illness:**\n",
    "\n",
    "Patient presented with a traumatic injury to his left hand, including total amputation of the left ring finger, near total amputation of the middle finger, comminuted fracture of the middle phalanx, and injury to the thumb. The patient underwent a replantation of the ring finger and revascularization of the middle finger, as well as an open reduction internal fixation of the fractures. The patient has been undergoing rehabilitation for the past three months and reports that his hand has been healing well.\n",
    "\n",
    "**Physical Examination:**\n",
    "\n",
    "Upon examination, the patient's left hand showed signs of a total amputation of the ring finger, near total amputation of the middle finger, and a comminuted fracture of the middle phalanx. The thumb also showed signs of injury. The patient's range of motion and sensation were normal. The patient's hand was found to be healing well with no signs of infection or complications.\n",
    "\n",
    "**Assessment:**\n",
    "\n",
    "The patient's condition is stable, and his hand is healing well. The patient has been able to return to work as a carpenter. The patient will continue with his rehabilitation and take care of his hand.\n",
    "\n",
    "**Plan:**\n",
    "\n",
    "The patient will continue with his rehabilitation and take care of his hand. He will also follow up with the doctor if he experiences any pain or discomfort. The patient will also be advised to return to the office if he notices any signs of infection or complications.\n",
    "\n",
    "**Medications:**\n",
    "\n",
    "None prescribed.\n",
    "\n",
    "**Follow-up:**\n",
    "\n",
    "The patient will follow up with the doctor in two weeks to assess the progress of his hand.\n",
    "\n",
    "**Signature:**\n",
    "\n",
    "[Doctor's Signature]</pre>\n",
    "</div>\n",
    "<p style=\"color: #ff6b6b; font-size: 11px; margin: 5px 0 0 0;\"><strong>Why this is rejected:</strong> Template format with headers • Placeholder text ([Patient's Name], [Doctor's Signature]) • Bullet points and verbose sections • Redundant information • 1,806 characters — too verbose • Requires editing before physician use</p>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \"http://nemo.test/v1/datasets\" \\\n",
    "   -H 'accept: application/json' \\\n",
    "   -H 'Content-Type: application/json' \\\n",
    "   -d '{\"name\": \"notes-dpo-format\", \"namespace\": \"default\", \"description\": \"Clinical notes DPO preference data\", \"files_url\": \"hf://datasets/default/notes-dpo-format\", \"project\": \"sample_project_for_notes_dpo\"}' | jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Find and scale down NIM deployment\n",
    "nim_deploy = subprocess.run(\n",
    "    \"kubectl get deployment -o name | grep modeldeployment | head -1\",\n",
    "    shell=True, capture_output=True, text=True\n",
    ")\n",
    "\n",
    "if nim_deploy.stdout.strip():\n",
    "    NIM_DEPLOYMENT = nim_deploy.stdout.strip().replace(\"deployment.apps/\", \"\")\n",
    "    print(f\"Found NIM deployment: {NIM_DEPLOYMENT}\")\n",
    "    subprocess.run(f\"kubectl scale deployment {NIM_DEPLOYMENT} --replicas=0\", shell=True)\n",
    "    print(\"Scaling down NIM...\")\n",
    "    \n",
    "    # Wait for pod to terminate\n",
    "    for i in range(12):\n",
    "        time.sleep(5)\n",
    "        pods = subprocess.run(\n",
    "            f\"kubectl get pods | grep {NIM_DEPLOYMENT[:30]} | grep -c Running\",\n",
    "            shell=True, capture_output=True, text=True\n",
    "        )\n",
    "        if int(pods.stdout.strip() or \"0\") == 0:\n",
    "            print(\"NIM paused - GPUs available for DPO training\")\n",
    "            break\n",
    "else:\n",
    "    print(\"No NIM deployment found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_job = client.customization.jobs.create(\n",
    "    config=\"meta/llama-3.1-8b-instruct@v1.0.0+80GB\",\n",
    "    dataset={\"name\": \"notes-dpo-format\", \"namespace\": \"default\"},\n",
    "    hyperparameters={\n",
    "        \"training_type\": \"dpo\",\n",
    "        \"finetuning_type\": \"all_weights\",\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 4,\n",
    "        \"learning_rate\": 5e-6,\n",
    "        \"dpo\": {\"beta\": 0.1}\n",
    "    },\n",
    "    project=\"test-notes-dpo-project\",\n",
    "    output_model=\"default/test-notes-dpo-model@v1\"\n",
    ")\n",
    "print(dpo_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor DPO job\n",
    "dpo_job_id = dpo_job.id\n",
    "job_status = None\n",
    "while job_status not in (\"completed\", \"failed\", \"cancelled\"):\n",
    "    status = client.customization.jobs.status(dpo_job_id)\n",
    "    job_status = status.status\n",
    "    print(job_status)\n",
    "    if job_status == \"failed\":\n",
    "        print(status.model_dump_json(indent=2))\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View DPO training results\n",
    "print(status.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart NIM for Evaluation\n",
    "\n",
    "Deploy the DPO full-weight model as a NIM for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy DPO model as NIM (uses all 8 GPUs)\n",
    "import requests\n",
    "\n",
    "DPO_MODEL = \"default/test-notes-dpo-model@v1\"\n",
    "DPO_DEPLOY_NAME = \"dpo-llama-8b\"\n",
    "\n",
    "# Scale down base NIM to free GPUs\n",
    "print(\"Scaling down base NIM to free GPUs...\")\n",
    "subprocess.run(\"kubectl scale deployment modeldeployment-meta-llama-3-1-8b-instruct --replicas=0\", shell=True)\n",
    "time.sleep(10)\n",
    "\n",
    "# Create DPO NIM deployment via REST API\n",
    "print(f\"Creating DPO NIM deployment for {DPO_MODEL}...\")\n",
    "resp = requests.post(\n",
    "    \"http://nemo.test/v1/deployment/model-deployments\",\n",
    "    json={\n",
    "        \"name\": DPO_DEPLOY_NAME,\n",
    "        \"namespace\": \"default\",\n",
    "        \"config\": {\n",
    "            \"model\": DPO_MODEL,\n",
    "            \"nim_deployment\": {\n",
    "                \"gpu\": 8,\n",
    "                \"image_name\": \"nvcr.io/nim/meta/llama-3.1-8b-instruct\",\n",
    "                \"image_tag\": \"1.8.3\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Response: {resp.json()}\")\n",
    "\n",
    "# Wait for DPO NIM to be ready\n",
    "print(\"\\nWaiting for DPO NIM (TensorRT compilation ~5-10 min)...\")\n",
    "for i in range(60):\n",
    "    try:\n",
    "        status = requests.get(f\"http://nemo.test/v1/deployment/model-deployments/default/{DPO_DEPLOY_NAME}\").json()\n",
    "        state = status.get(\"status_details\", {}).get(\"status\", \"unknown\")\n",
    "        print(f\"  [{i*10}s] Status: {state}\")\n",
    "        if state == \"ready\":\n",
    "            print(\"✓ DPO NIM ready!\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"  [{i*10}s] Checking... {e}\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO eval config using chosen_response from DPO validation data\n",
    "dpo_eval_config = {\n",
    "   \"type\": \"custom\",\n",
    "   \"params\": {\"parallelism\": 1},\n",
    "   \"tasks\": {\n",
    "      \"my-custom-task\": {\n",
    "         \"type\": \"completion\",\n",
    "         \"params\": {\"template\": {\"prompt\": \"{{prompt}}\", \"max_tokens\": 1024, \"temperature\": 0.7, \"top_p\": 0.9}},\n",
    "         \"dataset\": {\"files_url\": \"hf://datasets/default/notes-dpo-format/validation/val_dpo.jsonl\"},\n",
    "         \"metrics\": {\n",
    "            \"bleu\": {\"type\": \"bleu\", \"params\": {\"references\": [\"{{chosen_response}}\"]}},\n",
    "            \"llm-judge\": {\n",
    "               \"type\": \"llm-judge\",\n",
    "               \"params\": {\n",
    "                  \"model\": judge_model,\n",
    "                  \"template\": {\"messages\": [\n",
    "                     {\"role\": \"system\", \"content\": \"You are an expert evaluator for clinical documentation.\"},\n",
    "                     {\"role\": \"user\", \"content\": \"Calculate metrics for: Query: {{prompt}}\\nIdeal: {{chosen_response}}\\nModel: {{output_text}}\\nMetrics (0-100 each): 1.similarity_in_length 2.correctness 3.enough_information 4.succinct 5.professional_tone 6.clarity_directness\"}\n",
    "                  ]},\n",
    "                  \"structured_output\": {\"schema\": {\n",
    "                     \"type\": \"object\",\n",
    "                     \"properties\": {\n",
    "                        \"similarity_in_length\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 100},\n",
    "                        \"correctness\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 100},\n",
    "                        \"enough_information\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 100},\n",
    "                        \"succinct\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 100},\n",
    "                        \"professional_tone\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 100},\n",
    "                        \"clarity_directness\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 100}\n",
    "                     },\n",
    "                     \"required\": [\"similarity_in_length\", \"correctness\", \"enough_information\", \"succinct\", \"professional_tone\", \"clarity_directness\"],\n",
    "                     \"additionalProperties\": False\n",
    "                  }},\n",
    "                  \"scores\": {\n",
    "                     \"similarity_in_length\": {\"type\": \"integer\", \"parser\": {\"type\": \"json\", \"json_path\": \"similarity_in_length\"}},\n",
    "                     \"correctness\": {\"type\": \"integer\", \"parser\": {\"type\": \"json\", \"json_path\": \"correctness\"}},\n",
    "                     \"enough_information\": {\"type\": \"integer\", \"parser\": {\"type\": \"json\", \"json_path\": \"enough_information\"}},\n",
    "                     \"succinct\": {\"type\": \"integer\", \"parser\": {\"type\": \"json\", \"json_path\": \"succinct\"}},\n",
    "                     \"professional_tone\": {\"type\": \"integer\", \"parser\": {\"type\": \"json\", \"json_path\": \"professional_tone\"}},\n",
    "                     \"clarity_directness\": {\"type\": \"integer\", \"parser\": {\"type\": \"json\", \"json_path\": \"clarity_directness\"}}\n",
    "                  }\n",
    "               }\n",
    "            }\n",
    "         }\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "dpo_eval_job = client.evaluation.jobs.create(\n",
    "   target={\n",
    "      \"type\": \"model\",\n",
    "      \"model\": {\n",
    "         \"api_endpoint\": {\n",
    "            \"url\": \"http://modeldeployment-default-dpo-llama-8b:8000/v1/completions\",\n",
    "            \"model_id\": \"default/test-notes-dpo-model\"\n",
    "         }\n",
    "      }\n",
    "   },\n",
    "   config=dpo_eval_config\n",
    ")\n",
    "print(dpo_eval_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for DPO evaluation to complete\n",
    "dpo_eval_job_id = dpo_eval_job.id\n",
    "job_status = None\n",
    "while job_status not in (\"completed\", \"failed\", \"cancelled\"):\n",
    "   job = client.evaluation.jobs.retrieve(dpo_eval_job_id)\n",
    "   job_status = job.status\n",
    "   print(job_status)\n",
    "   if job_status == \"failed\":\n",
    "       print(job)\n",
    "   time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View DPO evaluation results\n",
    "results = client.evaluation.jobs.results(dpo_eval_job_id)\n",
    "print(results.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download DPO evaluation results\n",
    "results_zip = client.evaluation.jobs.download_results(dpo_eval_job_id)\n",
    "results_zip.write_to_file('result_after_dpo.zip')\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Real Example: Post-SFT vs Post-DPO — *Same Case from Cell 89*\n",
    "\n",
    "This continues the **Carpenter Hand Injury Case** from Cell 89, showing how DPO refines the SFT output into a more concise, physician-preferred style.\n",
    "\n",
    "####  Post-DPO Model Evaluation Metrics\n",
    "\n",
    "| Metric | Score | Interpretation |\n",
    "|--------|-------|----------------|\n",
    "| **Similarity in Length** | 95 | Excellent match to preferred length |\n",
    "| **Correctness** | 98 | Clinical information highly accurate |\n",
    "| **Enough Information** | 96 | All key details present |\n",
    "| **Succinct** | 90 | Significantly reduced verbosity |\n",
    "| **Professional Tone** | 98 | Clinical documentation style |\n",
    "| **Clarity & Directness** | 97 | Clear, direct communication |\n",
    "\n",
    "---\n",
    "\n",
    "#### Example Conversation (Input) — *Same as Cell 89*\n",
    "\n",
    "<div style=\"background: #1a1a2e; padding: 15px; border-radius: 8px; margin: 10px 0; \">\n",
    "<pre style=\"color: #a0a0a0; font-size: 12px; white-space: pre-wrap; margin: 0;\">Doctor: Good morning, what brings you here today?\n",
    "\n",
    "Patient: Hi, Doctor. I was in an accident with a saw while I was working as a carpenter and I need to check on my hand.\n",
    "\n",
    "Doctor: I see. Can you tell me what happened to your hand?\n",
    "\n",
    "Patient: I had a saw accident and my left ring finger was cut off, and my middle finger was almost cut off and my little finger was fractured, and my thumb was injured.\n",
    "\n",
    "Doctor: Hmm, I understand. How old are you?\n",
    "\n",
    "Patient: I am 22 years old.\n",
    "\n",
    "Doctor (checks the patient's hand): I see that you had a total amputation of your left ring finger and a near total amputation of your middle finger. And it looks like you had a comminuted fracture of your middle phalanx and an injury to your thumb.\n",
    "\n",
    "Patient: Yes, that's right.\n",
    "\n",
    "Doctor: I see that you underwent a replantation of your ring finger and a revascularization of your middle finger. And you also had an open reduction internal fixation of the fractures.\n",
    "\n",
    "Patient: Yes, that's correct.\n",
    "\n",
    "Doctor: How have you been feeling since the surgery?\n",
    "\n",
    "Patient: I've been feeling good. I've been going through rehabilitation for the past three months.\n",
    "\n",
    "Patient: It's been healing well. I've been able to go back to work as a carpenter.</pre>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "####  Post-SFT Output — *Same as Cell 89* (1,806 characters)\n",
    "\n",
    "<div style=\"background: #2a2a3e; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #ffd700; \">\n",
    "<pre style=\"color: #e0e0e0; font-size: 12px; white-space: pre-wrap; margin: 0;\">Here is a clinical note based on the conversation:\n",
    "\n",
    "**Patient:** [Patient's Name], 22-year-old male\n",
    "\n",
    "**Chief Complaint:** Traumatic injury to left hand from saw accident\n",
    "\n",
    "**History of Present Illness:**\n",
    "\n",
    "Patient presented with a traumatic injury to his left hand, including total amputation of the left ring finger, near total amputation of the middle finger, comminuted fracture of the middle phalanx, and injury to the thumb. The patient underwent a replantation of the ring finger and revascularization of the middle finger, as well as an open reduction internal fixation of the fractures. The patient has been undergoing rehabilitation for the past three months and reports that his hand has been healing well.\n",
    "\n",
    "**Physical Examination:**\n",
    "\n",
    "Upon examination, the patient's left hand showed signs of a total amputation of the ring finger, near total amputation of the middle finger, and a comminuted fracture of the middle phalanx. The thumb also showed signs of injury. The patient's range of motion and sensation were normal. The patient's hand was found to be healing well with no signs of infection or complications.\n",
    "\n",
    "**Assessment:**\n",
    "\n",
    "The patient's condition is stable, and his hand is healing well. The patient has been able to return to work as a carpenter.\n",
    "\n",
    "**Plan:**\n",
    "\n",
    "The patient will continue with his rehabilitation and take care of his hand.\n",
    "\n",
    "**Medications:** None prescribed.\n",
    "**Follow-up:** The patient will follow up with the doctor in two weeks.\n",
    "**Signature:** [Doctor's Signature]</pre>\n",
    "<p style=\"color: #ffd700; font-size: 11px; margin: 8px 0 0 0;\"><strong>Style issues:</strong>  Template format with headers •  Redundant sections •  Placeholder text [Patient's Name], [Doctor's Signature] •  1,806 characters — verbose</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "####  Post-DPO Output (Physician-preferred concise style) — 623 characters\n",
    "\n",
    "<div style=\"background: #1a3a2e; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #4ade80;\">\n",
    "<pre style=\"color: #e0e0e0; font-size: 12px; white-space: pre-wrap; margin: 0;\">This is 22 years old right handed male carpenter, his left hand was cut by electric saw sustained total amputation of his left ring finger just proximal to proximal interphalangeal joint & near total amputation of middle finger with cut both neurovascular junction at level of mid part of middle phalanx & open comminuted fracture of middle phalanx little finger with cut ulnar neurovascular bundle & tip injury thumb.\n",
    "\n",
    "Replantation of the ring, revascularization of middle & open reduction internal fixation of the fractures was done. After a period of rehabilitation for three months patient was back to his original work.</pre>\n",
    "<p style=\"color: #4ade80; font-size: 11px; margin: 8px 0 0 0;\"><strong>Style improvements:</strong>  Direct clinical narrative •  No template headers •  No placeholders •  Precise anatomical detail •  Concise at 623 characters (65% reduction from SFT) •  Professional surgical note style</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "###  Style Refinement: 65% Length Reduction\n",
    "\n",
    "```\n",
    "Post-SFT:  ████████████████████████████████████████  1,806 chars\n",
    "Post-DPO:  ██████████████                            623 chars  (65% reduction)\n",
    "```\n",
    "\n",
    "<div style=\"background: #16213e; padding: 15px; border-radius: 8px; border-left: 4px solid #ffd700; margin: 15px 0;\">\n",
    "<strong style=\"color: #ffd700;\"> Key Insight:</strong> <span style=\"color: #e0e0e0;\">SFT teaches the model <em>what</em> information to include (FORMAT). DPO refines <em>how</em> to present it, preferring concise, direct clinical prose with precise anatomical terminology over verbose templates (STYLE).</span>\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #1a1a2e; padding: 12px; border-radius: 6px; margin: 10px 0;\">\n",
    "<strong style=\"color: #00d4ff;\">The Complete Pipeline (Same Carpenter Hand Injury Example Throughout):</strong>\n",
    "<div style=\"color: #e0e0e0; margin-top: 8px;\">\n",
    "<strong style=\"color: #ff6b6b;\">Baseline (Cell 89)</strong> → Template format, repetitive, asks for input, missing details<br/>\n",
    "<strong style=\"color: #ffd700;\">↓ SFT (Cell 89)</strong> → Learns format, includes all details, but verbose with headers (1,806 chars)<br/>\n",
    "<strong style=\"color: #4ade80;\">↓ DPO (This cell)</strong> → Concise narrative, precise terminology, physician-ready (623 chars)\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
